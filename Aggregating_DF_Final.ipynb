{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import warnings\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data (data comes from cleaning the full dataset; see Clean_Full_Dataset.ipynb for details), drop any rows with NAs, and convert the 'CheckoutDate' column to a DateTime datatype. We also sort by CheckoutDate and reset the index; this step is unnecessary but helpful for viewing the data in chronological checkout order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>CleanedTitle</th>\n",
       "      <th>CleanedCreator</th>\n",
       "      <th>CheckoutDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>3</td>\n",
       "      <td>The rosary girls / Richard Montanari.</td>\n",
       "      <td>Montanari, Richard</td>\n",
       "      <td>Balzano Jessica Fictitious character Fiction, ...</td>\n",
       "      <td>Ballantine Books,</td>\n",
       "      <td>2005</td>\n",
       "      <td>therosarygirls</td>\n",
       "      <td>montanaririchard</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>2</td>\n",
       "      <td>Secrets of the millionaire mind : mastering th...</td>\n",
       "      <td>Eker, T. Harv</td>\n",
       "      <td>Money Psychological aspects, Millionaires Psyc...</td>\n",
       "      <td>HarperBusiness,</td>\n",
       "      <td>2005</td>\n",
       "      <td>secretsofthemillionairemind</td>\n",
       "      <td>ekerharvt</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>7</td>\n",
       "      <td>In the company of liars / David Ellis.</td>\n",
       "      <td>Ellis, David, 1967-</td>\n",
       "      <td>Thrillers Fiction</td>\n",
       "      <td>G.P. Putnam's Sons,</td>\n",
       "      <td>2005</td>\n",
       "      <td>inthecompanyofliars</td>\n",
       "      <td>davidellis</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>21</td>\n",
       "      <td>The motive / John Lescroart.</td>\n",
       "      <td>Lescroart, John T.</td>\n",
       "      <td>Hardy Dismas Fictitious character Fiction, Soc...</td>\n",
       "      <td>Dutton,</td>\n",
       "      <td>2005</td>\n",
       "      <td>themotive</td>\n",
       "      <td>johnlescroartt</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>1</td>\n",
       "      <td>The rottweiler [text (large print)] / Ruth Ren...</td>\n",
       "      <td>Rendell, Ruth, 1930-2015</td>\n",
       "      <td>Police England London Fiction, Lisson Grove Lo...</td>\n",
       "      <td>Thorndike Press,</td>\n",
       "      <td>2005</td>\n",
       "      <td>therottweiler</td>\n",
       "      <td>rendellruth</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UsageClass MaterialType  Checkouts  \\\n",
       "0   Physical         BOOK          3   \n",
       "1   Physical         BOOK          2   \n",
       "2   Physical         BOOK          7   \n",
       "3   Physical         BOOK         21   \n",
       "4   Physical         BOOK          1   \n",
       "\n",
       "                                               Title  \\\n",
       "0              The rosary girls / Richard Montanari.   \n",
       "1  Secrets of the millionaire mind : mastering th...   \n",
       "2             In the company of liars / David Ellis.   \n",
       "3                       The motive / John Lescroart.   \n",
       "4  The rottweiler [text (large print)] / Ruth Ren...   \n",
       "\n",
       "                    Creator  \\\n",
       "0        Montanari, Richard   \n",
       "1             Eker, T. Harv   \n",
       "2       Ellis, David, 1967-   \n",
       "3        Lescroart, John T.   \n",
       "4  Rendell, Ruth, 1930-2015   \n",
       "\n",
       "                                            Subjects            Publisher  \\\n",
       "0  Balzano Jessica Fictitious character Fiction, ...    Ballantine Books,   \n",
       "1  Money Psychological aspects, Millionaires Psyc...      HarperBusiness,   \n",
       "2                                  Thrillers Fiction  G.P. Putnam's Sons,   \n",
       "3  Hardy Dismas Fictitious character Fiction, Soc...              Dutton,   \n",
       "4  Police England London Fiction, Lisson Grove Lo...     Thorndike Press,   \n",
       "\n",
       "   PublicationYear                 CleanedTitle    CleanedCreator CheckoutDate  \n",
       "0             2005               therosarygirls  montanaririchard   2005-04-01  \n",
       "1             2005  secretsofthemillionairemind         ekerharvt   2005-04-01  \n",
       "2             2005          inthecompanyofliars        davidellis   2005-04-01  \n",
       "3             2005                    themotive    johnlescroartt   2005-04-01  \n",
       "4             2005                therottweiler       rendellruth   2005-04-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in cleaned data\n",
    "#df=pd.read_csv('data/Checkouts_2005_cleaned.csv')\n",
    "#df=pd.read_csv('data/Checkouts_2005_cleaned_w_colon.csv')\n",
    "df=pd.read_csv('data/Checkouts_2005_no_whitespace.csv')\n",
    "df = df.dropna()\n",
    "df['CheckoutDate'] = pd.to_datetime(df['CheckoutDate'])\n",
    "df = df.sort_values(by='CheckoutDate')\n",
    "df =df.reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Data: \n",
    "\n",
    "Our goal is to make a new dataset where each row corresponds to a unique set of\n",
    "(CleanedTitle, CleanedCreator, UsageClass, MaterialType). The dataframe will have a column for each month of checkout data we have (April 2005 - April 2024), where these columns contain the number of checkouts in that month for each book respectively. Note that we have data up to August 2024; however, the months of May 2024 and June 2024 are empty. Thus, we take the last month of data as April 2024. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a list of the months we have checkout data from, where each month is a string of the form MM/DD/YYYY. This list of strings will be used to populate the columns of our dataframe later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of the months we have checkout data from \n",
    "months_of_interest=pd.date_range(start='2005-04-01', end='2024-04-01',freq='MS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2005-04-01', '2005-05-01', '2005-06-01', '2005-07-01',\n",
      "               '2005-08-01', '2005-09-01', '2005-10-01', '2005-11-01',\n",
      "               '2005-12-01', '2006-01-01',\n",
      "               ...\n",
      "               '2023-07-01', '2023-08-01', '2023-09-01', '2023-10-01',\n",
      "               '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01',\n",
      "               '2024-03-01', '2024-04-01'],\n",
      "              dtype='datetime64[ns]', length=229, freq='MS')\n"
     ]
    }
   ],
   "source": [
    "print(months_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-04-01 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months_of_interest[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of all months as strings; will be used as column names later\n",
    "month_columns = months_of_interest.strftime('%m/%d/%Y')\n",
    "month_columns = month_columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-04-01 00:00:00\n",
      "2005-05-01 00:00:00\n",
      "2005-06-01 00:00:00\n",
      "2005-07-01 00:00:00\n",
      "2005-08-01 00:00:00\n",
      "2005-09-01 00:00:00\n",
      "2005-10-01 00:00:00\n",
      "2005-11-01 00:00:00\n",
      "2005-12-01 00:00:00\n",
      "2006-01-01 00:00:00\n",
      "2006-02-01 00:00:00\n",
      "2006-03-01 00:00:00\n",
      "2006-04-01 00:00:00\n",
      "2006-05-01 00:00:00\n",
      "2006-06-01 00:00:00\n",
      "2006-07-01 00:00:00\n",
      "2006-08-01 00:00:00\n",
      "2006-09-01 00:00:00\n",
      "2006-10-01 00:00:00\n",
      "2006-11-01 00:00:00\n",
      "2006-12-01 00:00:00\n",
      "2007-01-01 00:00:00\n",
      "2007-02-01 00:00:00\n",
      "2007-03-01 00:00:00\n",
      "2007-04-01 00:00:00\n",
      "2007-05-01 00:00:00\n",
      "2007-06-01 00:00:00\n",
      "2007-07-01 00:00:00\n",
      "2007-08-01 00:00:00\n",
      "2007-09-01 00:00:00\n",
      "2007-10-01 00:00:00\n",
      "2007-11-01 00:00:00\n",
      "2007-12-01 00:00:00\n",
      "2008-01-01 00:00:00\n",
      "2008-02-01 00:00:00\n",
      "2008-03-01 00:00:00\n",
      "2008-04-01 00:00:00\n",
      "2008-05-01 00:00:00\n",
      "2008-06-01 00:00:00\n",
      "2008-07-01 00:00:00\n",
      "2008-08-01 00:00:00\n",
      "2008-09-01 00:00:00\n",
      "2008-10-01 00:00:00\n",
      "2008-11-01 00:00:00\n",
      "2008-12-01 00:00:00\n",
      "2009-01-01 00:00:00\n",
      "2009-02-01 00:00:00\n",
      "2009-03-01 00:00:00\n",
      "2009-04-01 00:00:00\n",
      "2009-05-01 00:00:00\n",
      "2009-06-01 00:00:00\n",
      "2009-07-01 00:00:00\n",
      "2009-08-01 00:00:00\n",
      "2009-09-01 00:00:00\n",
      "2009-10-01 00:00:00\n",
      "2009-11-01 00:00:00\n",
      "2009-12-01 00:00:00\n",
      "2010-01-01 00:00:00\n",
      "2010-02-01 00:00:00\n",
      "2010-03-01 00:00:00\n",
      "2010-04-01 00:00:00\n",
      "2010-05-01 00:00:00\n",
      "2010-06-01 00:00:00\n",
      "2010-07-01 00:00:00\n",
      "2010-08-01 00:00:00\n",
      "2010-09-01 00:00:00\n",
      "2010-10-01 00:00:00\n",
      "2010-11-01 00:00:00\n",
      "2010-12-01 00:00:00\n",
      "2011-01-01 00:00:00\n",
      "2011-02-01 00:00:00\n",
      "2011-03-01 00:00:00\n",
      "2011-04-01 00:00:00\n",
      "2011-05-01 00:00:00\n",
      "2011-06-01 00:00:00\n",
      "2011-07-01 00:00:00\n",
      "2011-08-01 00:00:00\n",
      "2011-09-01 00:00:00\n",
      "2011-10-01 00:00:00\n",
      "2011-11-01 00:00:00\n",
      "2011-12-01 00:00:00\n",
      "2012-01-01 00:00:00\n",
      "2012-02-01 00:00:00\n",
      "2012-03-01 00:00:00\n",
      "2012-04-01 00:00:00\n",
      "2012-05-01 00:00:00\n",
      "2012-06-01 00:00:00\n",
      "2012-07-01 00:00:00\n",
      "2012-08-01 00:00:00\n",
      "2012-09-01 00:00:00\n",
      "2012-10-01 00:00:00\n",
      "2012-11-01 00:00:00\n",
      "2012-12-01 00:00:00\n",
      "2013-01-01 00:00:00\n",
      "2013-02-01 00:00:00\n",
      "2013-03-01 00:00:00\n",
      "2013-04-01 00:00:00\n",
      "2013-05-01 00:00:00\n",
      "2013-06-01 00:00:00\n",
      "2013-07-01 00:00:00\n",
      "2013-08-01 00:00:00\n",
      "2013-09-01 00:00:00\n",
      "2013-10-01 00:00:00\n",
      "2013-11-01 00:00:00\n",
      "2013-12-01 00:00:00\n",
      "2014-01-01 00:00:00\n",
      "2014-02-01 00:00:00\n",
      "2014-03-01 00:00:00\n",
      "2014-04-01 00:00:00\n",
      "2014-05-01 00:00:00\n",
      "2014-06-01 00:00:00\n",
      "2014-07-01 00:00:00\n",
      "2014-08-01 00:00:00\n",
      "2014-09-01 00:00:00\n",
      "2014-10-01 00:00:00\n",
      "2014-11-01 00:00:00\n",
      "2014-12-01 00:00:00\n",
      "2015-01-01 00:00:00\n",
      "2015-02-01 00:00:00\n",
      "2015-03-01 00:00:00\n",
      "2015-04-01 00:00:00\n",
      "2015-05-01 00:00:00\n",
      "2015-06-01 00:00:00\n",
      "2015-07-01 00:00:00\n",
      "2015-08-01 00:00:00\n",
      "2015-09-01 00:00:00\n",
      "2015-10-01 00:00:00\n",
      "2015-11-01 00:00:00\n",
      "2015-12-01 00:00:00\n",
      "2016-01-01 00:00:00\n",
      "2016-02-01 00:00:00\n",
      "2016-03-01 00:00:00\n",
      "2016-04-01 00:00:00\n",
      "2016-05-01 00:00:00\n",
      "2016-06-01 00:00:00\n",
      "2016-07-01 00:00:00\n",
      "2016-08-01 00:00:00\n",
      "2016-09-01 00:00:00\n",
      "2016-10-01 00:00:00\n",
      "2016-11-01 00:00:00\n",
      "2016-12-01 00:00:00\n",
      "2017-01-01 00:00:00\n",
      "2017-02-01 00:00:00\n",
      "2017-03-01 00:00:00\n",
      "2017-04-01 00:00:00\n",
      "2017-05-01 00:00:00\n",
      "2017-06-01 00:00:00\n",
      "2017-07-01 00:00:00\n",
      "2017-08-01 00:00:00\n",
      "2017-09-01 00:00:00\n",
      "2017-10-01 00:00:00\n",
      "2017-11-01 00:00:00\n",
      "2017-12-01 00:00:00\n",
      "2018-01-01 00:00:00\n",
      "2018-02-01 00:00:00\n",
      "2018-03-01 00:00:00\n",
      "2018-04-01 00:00:00\n",
      "2018-05-01 00:00:00\n",
      "2018-06-01 00:00:00\n",
      "2018-07-01 00:00:00\n",
      "2018-08-01 00:00:00\n",
      "2018-09-01 00:00:00\n",
      "2018-10-01 00:00:00\n",
      "2018-11-01 00:00:00\n",
      "2018-12-01 00:00:00\n",
      "2019-01-01 00:00:00\n",
      "2019-02-01 00:00:00\n",
      "2019-03-01 00:00:00\n",
      "2019-04-01 00:00:00\n",
      "2019-05-01 00:00:00\n",
      "2019-06-01 00:00:00\n",
      "2019-07-01 00:00:00\n",
      "2019-08-01 00:00:00\n",
      "2019-09-01 00:00:00\n",
      "2019-10-01 00:00:00\n",
      "2019-11-01 00:00:00\n",
      "2019-12-01 00:00:00\n",
      "2020-01-01 00:00:00\n",
      "2020-02-01 00:00:00\n",
      "2020-03-01 00:00:00\n",
      "2020-04-01 00:00:00\n",
      "2020-05-01 00:00:00\n",
      "2020-06-01 00:00:00\n",
      "2020-07-01 00:00:00\n",
      "2020-08-01 00:00:00\n",
      "2020-09-01 00:00:00\n",
      "2020-10-01 00:00:00\n",
      "2020-11-01 00:00:00\n",
      "2020-12-01 00:00:00\n",
      "2021-01-01 00:00:00\n",
      "2021-02-01 00:00:00\n",
      "2021-03-01 00:00:00\n",
      "2021-04-01 00:00:00\n",
      "2021-05-01 00:00:00\n",
      "2021-06-01 00:00:00\n",
      "2021-07-01 00:00:00\n",
      "2021-08-01 00:00:00\n",
      "2021-09-01 00:00:00\n",
      "2021-10-01 00:00:00\n",
      "2021-11-01 00:00:00\n",
      "2021-12-01 00:00:00\n",
      "2022-01-01 00:00:00\n",
      "2022-02-01 00:00:00\n",
      "2022-03-01 00:00:00\n",
      "2022-04-01 00:00:00\n",
      "2022-05-01 00:00:00\n",
      "2022-06-01 00:00:00\n",
      "2022-07-01 00:00:00\n",
      "2022-08-01 00:00:00\n",
      "2022-09-01 00:00:00\n",
      "2022-10-01 00:00:00\n",
      "2022-11-01 00:00:00\n",
      "2022-12-01 00:00:00\n",
      "2023-01-01 00:00:00\n",
      "2023-02-01 00:00:00\n",
      "2023-03-01 00:00:00\n",
      "2023-04-01 00:00:00\n",
      "2023-05-01 00:00:00\n",
      "2023-06-01 00:00:00\n",
      "2023-07-01 00:00:00\n",
      "2023-08-01 00:00:00\n",
      "2023-09-01 00:00:00\n",
      "2023-10-01 00:00:00\n",
      "2023-11-01 00:00:00\n",
      "2023-12-01 00:00:00\n",
      "2024-01-01 00:00:00\n",
      "2024-02-01 00:00:00\n",
      "2024-03-01 00:00:00\n",
      "2024-04-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Remove rows of df with checkout dates after '04/01/2024'\n",
    "df = df[df['CheckoutDate'] <= months_of_interest[-1]]\n",
    "\n",
    "#Verify we have the months we want\n",
    "for i in df.CheckoutDate.value_counts().index.sort_values():\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has a wide variety of Material Types: \n",
    "\n",
    "['BOOK' 'SOUNDDISC' 'SOUNDREC' 'SOUNDDISC, VIDEODISC' 'MUSIC' 'AUDIOBOOK'\n",
    " 'EBOOK' 'VIDEODISC' 'REGPRINT' 'ER' 'VISUAL' 'ATLAS' 'MAP' 'SOUNDCASS'\n",
    " 'VIDEO' 'ER, MAP' 'ER, SOUNDDISC' 'ER, SOUNDDISC, VIDEODISC'\n",
    " 'MUSICSNDREC' 'FLASHCARD, SOUNDDISC' 'ER, PRINT' 'ER, NONPROJGRAPH'\n",
    " 'ER, VIDEODISC' 'LARGEPRINT' 'NOTATEDMUSIC' 'MAP, VIEW'\n",
    " 'REGPRINT, VIDEOREC' 'KIT' 'REGPRINT, SOUNDDISC' 'ER, REGPRINT'\n",
    " 'FLASHCARD' 'UNSPECIFIED' 'MIXED' 'BOOK, ER' 'ER, SOUNDREC'\n",
    " 'ER, SOUNDDISC, SOUNDREC' 'PHOTO']\n",
    "\n",
    " To simplify our analysis, we take the five categories with the most checkouts and categorize all other types as 'OTHER'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valid material types\n",
    "material_types = ['BOOK','EBOOK','SOUNDDISC','VIDEODISC','AUDIOBOOK', 'OTHER']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BOOK' 'SOUNDDISC' 'SOUNDREC' 'SOUNDDISC, VIDEODISC' 'MUSIC' 'AUDIOBOOK'\n",
      " 'EBOOK' 'VIDEODISC' 'REGPRINT' 'ER' 'VISUAL' 'ATLAS' 'MAP' 'SOUNDCASS'\n",
      " 'VIDEO' 'ER, MAP' 'ER, SOUNDDISC' 'ER, SOUNDDISC, VIDEODISC'\n",
      " 'MUSICSNDREC' 'FLASHCARD, SOUNDDISC' 'ER, PRINT' 'ER, NONPROJGRAPH'\n",
      " 'ER, VIDEODISC' 'LARGEPRINT' 'NOTATEDMUSIC' 'MAP, VIEW'\n",
      " 'REGPRINT, VIDEOREC' 'KIT' 'REGPRINT, SOUNDDISC' 'ER, REGPRINT'\n",
      " 'FLASHCARD' 'UNSPECIFIED' 'MIXED' 'BOOK, ER' 'ER, SOUNDREC'\n",
      " 'ER, SOUNDDISC, SOUNDREC' 'PHOTO']\n",
      "['BOOK' 'SOUNDDISC' 'OTHER' 'AUDIOBOOK' 'EBOOK' 'VIDEODISC']\n"
     ]
    }
   ],
   "source": [
    "#Print original list of MaterialTypes found in dataset\n",
    "print(df.MaterialType.unique())\n",
    "#Filter out the material types not in material_types and replace them with \"OTHER\"\n",
    "df['MaterialType'] = df['MaterialType'].where(df['MaterialType'].isin(material_types), 'OTHER')\n",
    "#Print the new list of MaterialTypes found in dataset\n",
    "print(df.MaterialType.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>CleanedTitle</th>\n",
       "      <th>CleanedCreator</th>\n",
       "      <th>CheckoutDate</th>\n",
       "      <th>CheckoutDate_str</th>\n",
       "      <th>index_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>10</td>\n",
       "      <td>Why do I love these people? : honest and amazi...</td>\n",
       "      <td>Bronson, Po, 1964-</td>\n",
       "      <td>Families United States Case studies</td>\n",
       "      <td>Random House,</td>\n",
       "      <td>2005</td>\n",
       "      <td>whydoilovethesepeople</td>\n",
       "      <td>bronsonpo</td>\n",
       "      <td>2006-02-01</td>\n",
       "      <td>02/01/2006</td>\n",
       "      <td>whydoilovethesepeople , bronsonpo , Physical ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digital</td>\n",
       "      <td>AUDIOBOOK</td>\n",
       "      <td>1</td>\n",
       "      <td>Tales from Shakespeare (Unabridged)</td>\n",
       "      <td>Charles Lamb</td>\n",
       "      <td>Classic Literature, Fiction, Suspense</td>\n",
       "      <td>Sound Room Publishers, Inc.</td>\n",
       "      <td>2005</td>\n",
       "      <td>talesfromshakespeare</td>\n",
       "      <td>charleslamb</td>\n",
       "      <td>2006-05-01</td>\n",
       "      <td>05/01/2006</td>\n",
       "      <td>talesfromshakespeare , charleslamb , Digital ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>3</td>\n",
       "      <td>Washoku : recipes from the Japanese home kitch...</td>\n",
       "      <td>Andoh, Elizabeth</td>\n",
       "      <td>Cooking Japanese</td>\n",
       "      <td>Ten Speed Press,</td>\n",
       "      <td>2005</td>\n",
       "      <td>washoku</td>\n",
       "      <td>andohelizabeth</td>\n",
       "      <td>2006-12-01</td>\n",
       "      <td>12/01/2006</td>\n",
       "      <td>washoku , andohelizabeth , Physical , BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>1</td>\n",
       "      <td>Read and learn Bible / [stories retold by Eva ...</td>\n",
       "      <td>Moore, Eva</td>\n",
       "      <td>Bible Old Testament Juvenile literature, Bible...</td>\n",
       "      <td>Scholastic/American Bible Society,</td>\n",
       "      <td>2005</td>\n",
       "      <td>readandlearnbible</td>\n",
       "      <td>evamoore</td>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>02/01/2007</td>\n",
       "      <td>readandlearnbible , evamoore , Physical , BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Digital</td>\n",
       "      <td>AUDIOBOOK</td>\n",
       "      <td>1</td>\n",
       "      <td>Cause Celeb (Unabridged)</td>\n",
       "      <td>Helen Fielding</td>\n",
       "      <td>Fiction, Literature</td>\n",
       "      <td>Brilliance Audio, Inc.</td>\n",
       "      <td>2005</td>\n",
       "      <td>causeceleb</td>\n",
       "      <td>fieldinghelen</td>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>02/01/2007</td>\n",
       "      <td>causeceleb , fieldinghelen , Digital , AUDIOBOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UsageClass MaterialType  Checkouts  \\\n",
       "0   Physical         BOOK         10   \n",
       "1    Digital    AUDIOBOOK          1   \n",
       "2   Physical         BOOK          3   \n",
       "3   Physical         BOOK          1   \n",
       "4    Digital    AUDIOBOOK          1   \n",
       "\n",
       "                                               Title             Creator  \\\n",
       "0  Why do I love these people? : honest and amazi...  Bronson, Po, 1964-   \n",
       "1                Tales from Shakespeare (Unabridged)        Charles Lamb   \n",
       "2  Washoku : recipes from the Japanese home kitch...    Andoh, Elizabeth   \n",
       "3  Read and learn Bible / [stories retold by Eva ...          Moore, Eva   \n",
       "4                           Cause Celeb (Unabridged)      Helen Fielding   \n",
       "\n",
       "                                            Subjects  \\\n",
       "0                Families United States Case studies   \n",
       "1              Classic Literature, Fiction, Suspense   \n",
       "2                                   Cooking Japanese   \n",
       "3  Bible Old Testament Juvenile literature, Bible...   \n",
       "4                                Fiction, Literature   \n",
       "\n",
       "                            Publisher  PublicationYear           CleanedTitle  \\\n",
       "0                       Random House,             2005  whydoilovethesepeople   \n",
       "1         Sound Room Publishers, Inc.             2005   talesfromshakespeare   \n",
       "2                    Ten Speed Press,             2005                washoku   \n",
       "3  Scholastic/American Bible Society,             2005      readandlearnbible   \n",
       "4              Brilliance Audio, Inc.             2005             causeceleb   \n",
       "\n",
       "   CleanedCreator CheckoutDate CheckoutDate_str  \\\n",
       "0       bronsonpo   2006-02-01       02/01/2006   \n",
       "1     charleslamb   2006-05-01       05/01/2006   \n",
       "2  andohelizabeth   2006-12-01       12/01/2006   \n",
       "3        evamoore   2007-02-01       02/01/2007   \n",
       "4   fieldinghelen   2007-02-01       02/01/2007   \n",
       "\n",
       "                                           index_str  \n",
       "0  whydoilovethesepeople , bronsonpo , Physical ,...  \n",
       "1  talesfromshakespeare , charleslamb , Digital ,...  \n",
       "2         washoku , andohelizabeth , Physical , BOOK  \n",
       "3     readandlearnbible , evamoore , Physical , BOOK  \n",
       "4   causeceleb , fieldinghelen , Digital , AUDIOBOOK  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample dataframe used for priliminary testing\n",
    "df_sample = df.sample(1000)\n",
    "df_sample = df_sample.sort_values(by='CheckoutDate')\n",
    "df_sample =df_sample.reset_index(drop=True)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the unique sets from (CleanedTitle, CleanedCreator, UsageClass, MaterialType) using value_counts(). We see that we have 621171 (715720 in the case we don't filter out colon parts of title) different possible combinations of these features out of the ~25 million rows in the dataframe. Note that when we only used unique pairs of (CleanedTitle, CleanedCreator), we had around 440,000 different combinations. \n",
    "\n",
    "Update: in the event, we remove whitespace from CleanedTitle and CleanedCreator, we obtain 618128 unique sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609183, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the unique sets from (CleanedTitle, CleanedCreator, UsageClass, MaterialType)\n",
    "pairs = df[['CleanedTitle', 'CleanedCreator','UsageClass', 'MaterialType']].value_counts().reset_index()\n",
    "pairs = pairs.drop(columns='count')\n",
    "    \n",
    "pairs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a numpy array to store the checkout data for each month with rows corresponding to the rows in pairs and columns corresponding to the month in month_columns. We will then convert this to a dataframe to be merged with pairs later, which is significantly faster than updating pairs along the way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numpy array of zeros to store the number of checkouts in each month\n",
    "#Rows: indicate corresponding row in pairs\n",
    "#Columns: indicate corresponding month in month_columns\n",
    "months_count = np.zeros((pairs.shape[0], len(month_columns)),dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Checkouts', 'Title', 'Creator', 'Subjects', 'Publisher', 'PublicationYear', 'CheckoutDate']\n"
     ]
    }
   ],
   "source": [
    "#Get the column names of the features we want to add back in\n",
    "features = df.columns.to_list()\n",
    "\n",
    "#Remove the column names we already have in pairs\n",
    "features.remove('CleanedTitle')\n",
    "features.remove('CleanedCreator')\n",
    "features.remove('UsageClass')\n",
    "features.remove('MaterialType')\n",
    "\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main processing is done in the cell below: \n",
    "### Preprocessing: \n",
    "To speed up the runtime, we create a few columns with corresponding dictionaries that will enable us to grab row/column indices without searching through the dataframe. We use dictionaries because they are implemented via a hash map so that the average lookup time is O(1), compared with the O(N) we would need if we searched through the dataframe directly. The 'CheckoutDate_str' column converts the 'CheckoutDate' to a string that matches the month strings in month_columns; the dictionary date_to_idx will allow us to go from this string to the appropriate column index of the month we want to update in month_counts. The column 'index_str' contains the unique combination of the (CleanedTitle, CleanedCreator, UsageClass, MaterialType) converted to a single string separated by commas. This simplifies the processing so that we only need to consider one column from the row we have instead of four. We use this column and the indices in pairs to create a dictionary pairs_lookup which will allow us to go from the 'index_str' in df to the corresponding row index in pairs that it corresponds to. This index will be used to update month_counts and the other feature data for each row in pairs. Finally we initialize an array of zeros called filled, which signifies if the additional data corresponding to the column names found in features has been found for each row in pairs. Since df is sorted by CheckoutDate and .apply() is applied top down (first row to last row), we should grab the first CheckoutDate for the book and use its features information to update the row. Note that there is no guarentee that all books of type (CleanedTitle, CleanedCreator, UsageClass, MaterialType) have the same Publisher, Subject, PublicationYear, etc., but they should be similar so we choose to grab the first one. \n",
    "\n",
    "### Main Processing: \n",
    "updates_months_full is applied to each row of our dataframe df via df.apply(). As it traverses each row, it updates month_counts month index and pairs index it obtains from the date_to_idx and pairs_lookup dictionaries based on the 'CheckoutDate_str' and 'index_str' columns of the row. Additionally, it checks if we have found the additional data corresponding to the column names in features by checking the appropriate index in filled. If not, we return the features values from the row in addition to the row index of pairs. \n",
    "\n",
    "### Output: \n",
    "After applying updates_months_full to each row in df, the months_count array will contain checkout data from each month for each row in pairs. Additionally, for each row in pairs, updates will contain the corresponding features column information as a list of lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [161204, 3, The rosary girls / Richard Montana...\n",
       "1    [2697, 2, Secrets of the millionaire mind : ma...\n",
       "2    [61033, 7, In the company of liars / David Ell...\n",
       "3    [23674, 21, The motive / John Lescroart., Lesc...\n",
       "4    [146945, 1, The rottweiler [text (large print)...\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'CheckoutDate' to string in the desired format beforehand\n",
    "df['CheckoutDate_str'] = df['CheckoutDate'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "#Create columns for easier lookup in pairs and df; we treat this column as an index column \n",
    "pairs['index_str'] = pairs['CleanedTitle'] + \" , \" + pairs['CleanedCreator'] + \" , \" \\\n",
    "    + pairs['UsageClass'] + \" , \" + pairs['MaterialType']\n",
    "\n",
    "df['index_str'] =  df['CleanedTitle'] + \" , \" + df['CleanedCreator'] + \" , \" \\\n",
    "                 + df['UsageClass'] + \" , \" + df['MaterialType']\n",
    "\n",
    "#Create dictionary with keys given by index_str and values the corresponding index in pairs\n",
    "vals = pairs['index_str'].values\n",
    "indices = pairs.index\n",
    "pairs_lookup = dict(zip(vals, indices))\n",
    "\n",
    "#Dictionary to go from CheckoutDate_str to index in list of months\n",
    "date_to_idx = {date_str: idx for idx, date_str in enumerate(month_columns)}\n",
    "\n",
    "\n",
    "\n",
    "#Create array indicating which rows of pairs we have already filled in\n",
    "# 1 indicates we already filled it; 0 indicates we have not\n",
    "filled= [0] * len(indices)\n",
    "\n",
    "#Function to aggregate all the needed info\n",
    "def update_months_full(row):\n",
    "    #Update months count with checkout information\n",
    "    if row['CheckoutDate_str'] in date_to_idx:\n",
    "        date_idx  = date_to_idx[row['CheckoutDate_str']]\n",
    "    #Only take the months in the month_columns list; else drop row\n",
    "    else:\n",
    "        print(row['CheckoutDate_str'])\n",
    "        return None\n",
    "    pairs_idx = pairs_lookup[row['index_str']]\n",
    "    months_count[pairs_idx, date_idx] +=  row['Checkouts']\n",
    "\n",
    "    #Update additional information \n",
    "    title_creator_str = row['index_str']\n",
    "    #Check if we have updated the row yet; if not, update it\n",
    "    if filled[pairs_lookup[title_creator_str]]==0:\n",
    "        #Change indicator to 1 to indicate we have visited row\n",
    "        filled[pairs_lookup[title_creator_str]]=1\n",
    "        #Return the index in pairs with the corresponding features from df\n",
    "        return list(np.insert(row[features].values, 0, pairs_lookup[title_creator_str]))\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Apply the update_row function to each row in df\n",
    "updates = df.apply(update_months_full, axis=1)\n",
    "updates = updates.dropna()\n",
    "assert(updates.shape[0]==pairs.shape[0])\n",
    "updates.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609183\n",
      "609183\n"
     ]
    }
   ],
   "source": [
    "print(updates.shape[0])\n",
    "print(pairs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(609183, 5)\n",
      "(609183,)\n"
     ]
    }
   ],
   "source": [
    "#Make sure pairs and updates have the same number of rows\n",
    "print(pairs.shape)\n",
    "print(updates.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the information we need, we will create dataframes for updates and month_counts and merge them with pairs. We create dataframes via pd.DataFrame on month_counts and updates. updates already contains an index column which corresponds to the indices in pairs. To merge on these indices, we create corresponding 'index' columns in pairs and months_df via reset_index(). Note that the indicies of months_df already match those of pairs due to the construction of month_counts.  Finally, we merge updates_df with pairs and then the result of that with month_df on the index column to obtain the final dataframe merged_df. We drop some of the extra columns we created for processing and finally write the data to the file cleaned_months_with_types.csv in the data folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'Checkouts', 'Title', 'Creator', 'Subjects', 'Publisher', 'PublicationYear', 'CheckoutDate']\n"
     ]
    }
   ],
   "source": [
    "# Features we obtained in updates \n",
    "# We added a column for the corresponding index of pairs, so we add the column name here\n",
    "features_new = ['index', *features]\n",
    "print(features_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>CleanedTitle</th>\n",
       "      <th>CleanedCreator</th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>MaterialType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fancynancy</td>\n",
       "      <td>connorjaneo</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yugioh</td>\n",
       "      <td>kazukitakahashi</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thewalkingdead</td>\n",
       "      <td>kirkmanrobert</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nationalgeographicreaders</td>\n",
       "      <td>lauramarsh</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>avatar</td>\n",
       "      <td>geneluenyang</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index               CleanedTitle   CleanedCreator UsageClass MaterialType\n",
       "0      0                 fancynancy      connorjaneo   Physical         BOOK\n",
       "1      1                     yugioh  kazukitakahashi   Physical         BOOK\n",
       "2      2             thewalkingdead    kirkmanrobert   Physical         BOOK\n",
       "3      3  nationalgeographicreaders       lauramarsh    Digital        EBOOK\n",
       "4      4                     avatar     geneluenyang    Digital        EBOOK"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the extra column we made for indexing convenience\n",
    "pairs = pairs.drop(columns=['index_str'])\n",
    "\n",
    "#Add column with index of each row in pairs for merging \n",
    "pairs = pairs.reset_index()\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Checkouts</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>CheckoutDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161204</td>\n",
       "      <td>3</td>\n",
       "      <td>The rosary girls / Richard Montanari.</td>\n",
       "      <td>Montanari, Richard</td>\n",
       "      <td>Balzano Jessica Fictitious character Fiction, ...</td>\n",
       "      <td>Ballantine Books,</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2697</td>\n",
       "      <td>2</td>\n",
       "      <td>Secrets of the millionaire mind : mastering th...</td>\n",
       "      <td>Eker, T. Harv</td>\n",
       "      <td>Money Psychological aspects, Millionaires Psyc...</td>\n",
       "      <td>HarperBusiness,</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61033</td>\n",
       "      <td>7</td>\n",
       "      <td>In the company of liars / David Ellis.</td>\n",
       "      <td>Ellis, David, 1967-</td>\n",
       "      <td>Thrillers Fiction</td>\n",
       "      <td>G.P. Putnam's Sons,</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23674</td>\n",
       "      <td>21</td>\n",
       "      <td>The motive / John Lescroart.</td>\n",
       "      <td>Lescroart, John T.</td>\n",
       "      <td>Hardy Dismas Fictitious character Fiction, Soc...</td>\n",
       "      <td>Dutton,</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146945</td>\n",
       "      <td>1</td>\n",
       "      <td>The rottweiler [text (large print)] / Ruth Ren...</td>\n",
       "      <td>Rendell, Ruth, 1930-2015</td>\n",
       "      <td>Police England London Fiction, Lisson Grove Lo...</td>\n",
       "      <td>Thorndike Press,</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Checkouts                                              Title  \\\n",
       "0  161204          3              The rosary girls / Richard Montanari.   \n",
       "1    2697          2  Secrets of the millionaire mind : mastering th...   \n",
       "2   61033          7             In the company of liars / David Ellis.   \n",
       "3   23674         21                       The motive / John Lescroart.   \n",
       "4  146945          1  The rottweiler [text (large print)] / Ruth Ren...   \n",
       "\n",
       "                    Creator  \\\n",
       "0        Montanari, Richard   \n",
       "1             Eker, T. Harv   \n",
       "2       Ellis, David, 1967-   \n",
       "3        Lescroart, John T.   \n",
       "4  Rendell, Ruth, 1930-2015   \n",
       "\n",
       "                                            Subjects            Publisher  \\\n",
       "0  Balzano Jessica Fictitious character Fiction, ...    Ballantine Books,   \n",
       "1  Money Psychological aspects, Millionaires Psyc...      HarperBusiness,   \n",
       "2                                  Thrillers Fiction  G.P. Putnam's Sons,   \n",
       "3  Hardy Dismas Fictitious character Fiction, Soc...              Dutton,   \n",
       "4  Police England London Fiction, Lisson Grove Lo...     Thorndike Press,   \n",
       "\n",
       "   PublicationYear CheckoutDate  \n",
       "0             2005   2005-04-01  \n",
       "1             2005   2005-04-01  \n",
       "2             2005   2005-04-01  \n",
       "3             2005   2005-04-01  \n",
       "4             2005   2005-04-01  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create updates dataframe to be joined with pairs\n",
    "#The index column corresponds to the index column of pairs\n",
    "updates_df =pd.DataFrame(updates.to_list(), columns=features_new)\n",
    "updates_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>04/01/2005</th>\n",
       "      <th>05/01/2005</th>\n",
       "      <th>06/01/2005</th>\n",
       "      <th>07/01/2005</th>\n",
       "      <th>08/01/2005</th>\n",
       "      <th>09/01/2005</th>\n",
       "      <th>10/01/2005</th>\n",
       "      <th>11/01/2005</th>\n",
       "      <th>12/01/2005</th>\n",
       "      <th>...</th>\n",
       "      <th>07/01/2023</th>\n",
       "      <th>08/01/2023</th>\n",
       "      <th>09/01/2023</th>\n",
       "      <th>10/01/2023</th>\n",
       "      <th>11/01/2023</th>\n",
       "      <th>12/01/2023</th>\n",
       "      <th>01/01/2024</th>\n",
       "      <th>02/01/2024</th>\n",
       "      <th>03/01/2024</th>\n",
       "      <th>04/01/2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>54</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>151</td>\n",
       "      <td>176</td>\n",
       "      <td>169</td>\n",
       "      <td>137</td>\n",
       "      <td>166</td>\n",
       "      <td>190</td>\n",
       "      <td>246</td>\n",
       "      <td>382</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  04/01/2005  05/01/2005  06/01/2005  07/01/2005  08/01/2005  \\\n",
       "0      0           0           0           0           0           0   \n",
       "1      1           0           0           0           0           0   \n",
       "2      2           0           0           0           0           0   \n",
       "3      3           0           0           0           0           0   \n",
       "4      4           0           0           0           0           0   \n",
       "\n",
       "   09/01/2005  10/01/2005  11/01/2005  12/01/2005  ...  07/01/2023  \\\n",
       "0           0           0           0           0  ...          86   \n",
       "1           0           0           0           0  ...           4   \n",
       "2           0           0           0           0  ...           4   \n",
       "3           0           0           0           0  ...           2   \n",
       "4           0           0           0           0  ...         210   \n",
       "\n",
       "   08/01/2023  09/01/2023  10/01/2023  11/01/2023  12/01/2023  01/01/2024  \\\n",
       "0          90          80          86          82          52          71   \n",
       "1          15           4           7           5           3           1   \n",
       "2           4           6           7           6           6           7   \n",
       "3           5           2           6           2           3           4   \n",
       "4         151         176         169         137         166         190   \n",
       "\n",
       "   02/01/2024  03/01/2024  04/01/2024  \n",
       "0          69          54          68  \n",
       "1           2           1           1  \n",
       "2          14          15           1  \n",
       "3           4           2           5  \n",
       "4         246         382         348  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create months dataframe containing the counts for each month; to be joined with pairs\n",
    "# Note arrays index with (0,0) as top left so the index column is aligned with the index\n",
    "# columns of pairs\n",
    "months_df = pd.DataFrame(months_count, columns=month_columns)\n",
    "#Add index column to match with pairs\n",
    "months_df = months_df.reset_index()\n",
    "months_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>PublicationYear</th>\n",
       "      <th>CheckoutDate</th>\n",
       "      <th>CleanedTitle</th>\n",
       "      <th>CleanedCreator</th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>...</th>\n",
       "      <th>07/01/2023</th>\n",
       "      <th>08/01/2023</th>\n",
       "      <th>09/01/2023</th>\n",
       "      <th>10/01/2023</th>\n",
       "      <th>11/01/2023</th>\n",
       "      <th>12/01/2023</th>\n",
       "      <th>01/01/2024</th>\n",
       "      <th>02/01/2024</th>\n",
       "      <th>03/01/2024</th>\n",
       "      <th>04/01/2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>Fancy Nancy / by Jane O'Connor ; pictures by R...</td>\n",
       "      <td>O'Connor, Jane</td>\n",
       "      <td>Fancy Nancy Fictitious character Juvenile fict...</td>\n",
       "      <td>HarperCollins,</td>\n",
       "      <td>2006</td>\n",
       "      <td>2006-03-01</td>\n",
       "      <td>fancynancy</td>\n",
       "      <td>connorjaneo</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>54</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12978</th>\n",
       "      <td>Yu-Gi-Oh! : duelist. Vol. 12, Magician vs. mag...</td>\n",
       "      <td>Takahashi, Kazuki, 1961-</td>\n",
       "      <td>Games Comic books strips etc Juvenile literatu...</td>\n",
       "      <td>Viz Media,</td>\n",
       "      <td>2005</td>\n",
       "      <td>2006-08-01</td>\n",
       "      <td>yugioh</td>\n",
       "      <td>kazukitakahashi</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45510</th>\n",
       "      <td>The walking dead . [Volume 2, Miles behind us]...</td>\n",
       "      <td>Kirkman, Robert</td>\n",
       "      <td>Zombies Comic books strips etc, Survivalism Co...</td>\n",
       "      <td>Image Comics,</td>\n",
       "      <td>2006</td>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>thewalkingdead</td>\n",
       "      <td>kirkmanrobert</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285605</th>\n",
       "      <td>National Geographic Readers: Lizards</td>\n",
       "      <td>Laura Marsh</td>\n",
       "      <td>Beginning Reader, Juvenile Nonfiction, Nature</td>\n",
       "      <td>Random House, Inc.</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>nationalgeographicreaders</td>\n",
       "      <td>lauramarsh</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296436</th>\n",
       "      <td>Avatar: The Last Airbender - Smoke and Shadow,...</td>\n",
       "      <td>Gene Luen Yang</td>\n",
       "      <td>Comic and Graphic Books, Juvenile Fiction, Juv...</td>\n",
       "      <td>Random House, Inc.</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>avatar</td>\n",
       "      <td>geneluenyang</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>151</td>\n",
       "      <td>176</td>\n",
       "      <td>169</td>\n",
       "      <td>137</td>\n",
       "      <td>166</td>\n",
       "      <td>190</td>\n",
       "      <td>246</td>\n",
       "      <td>382</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title  \\\n",
       "8266    Fancy Nancy / by Jane O'Connor ; pictures by R...   \n",
       "12978   Yu-Gi-Oh! : duelist. Vol. 12, Magician vs. mag...   \n",
       "45510   The walking dead . [Volume 2, Miles behind us]...   \n",
       "285605               National Geographic Readers: Lizards   \n",
       "296436  Avatar: The Last Airbender - Smoke and Shadow,...   \n",
       "\n",
       "                         Creator  \\\n",
       "8266              O'Connor, Jane   \n",
       "12978   Takahashi, Kazuki, 1961-   \n",
       "45510            Kirkman, Robert   \n",
       "285605               Laura Marsh   \n",
       "296436            Gene Luen Yang   \n",
       "\n",
       "                                                 Subjects           Publisher  \\\n",
       "8266    Fancy Nancy Fictitious character Juvenile fict...      HarperCollins,   \n",
       "12978   Games Comic books strips etc Juvenile literatu...          Viz Media,   \n",
       "45510   Zombies Comic books strips etc, Survivalism Co...       Image Comics,   \n",
       "285605      Beginning Reader, Juvenile Nonfiction, Nature  Random House, Inc.   \n",
       "296436  Comic and Graphic Books, Juvenile Fiction, Juv...  Random House, Inc.   \n",
       "\n",
       "        PublicationYear CheckoutDate               CleanedTitle  \\\n",
       "8266               2006   2006-03-01                 fancynancy   \n",
       "12978              2005   2006-08-01                     yugioh   \n",
       "45510              2006   2008-10-01             thewalkingdead   \n",
       "285605             2015   2015-07-01  nationalgeographicreaders   \n",
       "296436             2015   2015-10-01                     avatar   \n",
       "\n",
       "         CleanedCreator UsageClass MaterialType  ...  07/01/2023  08/01/2023  \\\n",
       "8266        connorjaneo   Physical         BOOK  ...          86          90   \n",
       "12978   kazukitakahashi   Physical         BOOK  ...           4          15   \n",
       "45510     kirkmanrobert   Physical         BOOK  ...           4           4   \n",
       "285605       lauramarsh    Digital        EBOOK  ...           2           5   \n",
       "296436     geneluenyang    Digital        EBOOK  ...         210         151   \n",
       "\n",
       "        09/01/2023  10/01/2023  11/01/2023  12/01/2023  01/01/2024  \\\n",
       "8266            80          86          82          52          71   \n",
       "12978            4           7           5           3           1   \n",
       "45510            6           7           6           6           7   \n",
       "285605           2           6           2           3           4   \n",
       "296436         176         169         137         166         190   \n",
       "\n",
       "        02/01/2024  03/01/2024  04/01/2024  \n",
       "8266            69          54          68  \n",
       "12978            2           1           1  \n",
       "45510           14          15           1  \n",
       "285605           4           2           5  \n",
       "296436         246         382         348  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged1_df = pd.merge(updates_df, pairs, on='index')\n",
    "merged_df = pd.merge(merged1_df, months_df, on='index')\n",
    "\n",
    "#Sort by index so that when \n",
    "merged_df = merged_df.sort_values(by='index')\n",
    "#Remove the index and Checkouts columns as they are unnecessary. \n",
    "merged_df = merged_df.drop(columns=['index', 'Checkouts'])\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>CleanedTitle</th>\n",
       "      <th>CleanedCreator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>Fancy Nancy / by Jane O'Connor ; pictures by R...</td>\n",
       "      <td>O'Connor, Jane</td>\n",
       "      <td>fancynancy</td>\n",
       "      <td>connorjaneo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12978</th>\n",
       "      <td>Yu-Gi-Oh! : duelist. Vol. 12, Magician vs. mag...</td>\n",
       "      <td>Takahashi, Kazuki, 1961-</td>\n",
       "      <td>yugioh</td>\n",
       "      <td>kazukitakahashi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45510</th>\n",
       "      <td>The walking dead . [Volume 2, Miles behind us]...</td>\n",
       "      <td>Kirkman, Robert</td>\n",
       "      <td>thewalkingdead</td>\n",
       "      <td>kirkmanrobert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285605</th>\n",
       "      <td>National Geographic Readers: Lizards</td>\n",
       "      <td>Laura Marsh</td>\n",
       "      <td>nationalgeographicreaders</td>\n",
       "      <td>lauramarsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296436</th>\n",
       "      <td>Avatar: The Last Airbender - Smoke and Shadow,...</td>\n",
       "      <td>Gene Luen Yang</td>\n",
       "      <td>avatar</td>\n",
       "      <td>geneluenyang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214882</th>\n",
       "      <td>The Year's Best Science Fiction: Fifth Annual ...</td>\n",
       "      <td>Gardner Dozois</td>\n",
       "      <td>theyearsbestsciencefiction</td>\n",
       "      <td>dozoisgardner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12113</th>\n",
       "      <td>Ranma 1/2 Vol. 34 / story &amp; art by Rumiko Taka...</td>\n",
       "      <td>Takahashi, Rumiko, 1957-</td>\n",
       "      <td>ranma1</td>\n",
       "      <td>rumikotakahashi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200986</th>\n",
       "      <td>Fly Guy presents : sharks / Tedd Arnold.</td>\n",
       "      <td>Arnold, Tedd</td>\n",
       "      <td>flyguypresents</td>\n",
       "      <td>arnoldtedd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220080</th>\n",
       "      <td>Magi : the labyrinth of magic. 1 / story &amp; art...</td>\n",
       "      <td>Ōtaka, Shinobu</td>\n",
       "      <td>magi</td>\n",
       "      <td>shinobuōtaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175438</th>\n",
       "      <td>Invincible : ultimate collection. Volume 2 / c...</td>\n",
       "      <td>Kirkman, Robert</td>\n",
       "      <td>invincible</td>\n",
       "      <td>kirkmanrobert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140722</th>\n",
       "      <td>Pretty guardian : Sailor Moon. 1 / [Naoko Take...</td>\n",
       "      <td>Takeuchi, Naoko</td>\n",
       "      <td>prettyguardian</td>\n",
       "      <td>naokotakeuchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>Dungeon : zenith. Vol. 2, The barbarian prince...</td>\n",
       "      <td>Sfar, Joann</td>\n",
       "      <td>dungeon</td>\n",
       "      <td>joannsfar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53431</th>\n",
       "      <td>Gantz. [2] / story and art by Hiroya Oku ; [tr...</td>\n",
       "      <td>Oku, Hiroya</td>\n",
       "      <td>gantz</td>\n",
       "      <td>hiroyaoku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Cork &amp; Fuzz / by Dori Chaconas ; illustrated b...</td>\n",
       "      <td>Chaconas, Dori, 1938-</td>\n",
       "      <td>corkfuzz</td>\n",
       "      <td>chaconasdori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>The night before Christmas / by Clement Clarke...</td>\n",
       "      <td>Moore, Clement Clarke, 1779-1863</td>\n",
       "      <td>thenightbeforechristmas</td>\n",
       "      <td>clarkeclementmoore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54909</th>\n",
       "      <td>Pluto : Urasawa x Tezuka. 001 / by Naoki Urasa...</td>\n",
       "      <td>Urasawa, Naoki, 1960-</td>\n",
       "      <td>pluto</td>\n",
       "      <td>naokiurasawa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206259</th>\n",
       "      <td>Hana-Kimi : for you in full blossom. 3 / story...</td>\n",
       "      <td>Nakajo, Hisaya</td>\n",
       "      <td>hanakimi</td>\n",
       "      <td>hisayanakajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90682</th>\n",
       "      <td>Library wars : Love &amp; war. 1 / story and art b...</td>\n",
       "      <td>Yumi, Kiiro</td>\n",
       "      <td>librarywars</td>\n",
       "      <td>kiiroyumi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262025</th>\n",
       "      <td>Noragami : stray god. Volume 1 / Adachitoka ; ...</td>\n",
       "      <td>Adachi, Toka</td>\n",
       "      <td>noragami</td>\n",
       "      <td>adachitoka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>Pride and Prejudice (World Digital Library Edi...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>prideandprejudice</td>\n",
       "      <td>austenjane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75867</th>\n",
       "      <td>Rin-Ne. [1] / story and art by Rumiko Takahash...</td>\n",
       "      <td>Takahashi, Rumiko, 1957-</td>\n",
       "      <td>rinne</td>\n",
       "      <td>rumikotakahashi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11415</th>\n",
       "      <td>BACH, JS: Brandenburg Concertos, Vol  2</td>\n",
       "      <td>Johann Sebastian Bach</td>\n",
       "      <td>bachjs</td>\n",
       "      <td>bachjohannsebastian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7116</th>\n",
       "      <td>Moby Dick (World Digital Library Edition)</td>\n",
       "      <td>Herman Melville</td>\n",
       "      <td>mobydick</td>\n",
       "      <td>hermanmelville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87975</th>\n",
       "      <td>Pandora hearts. [2] / Jun Mochizuki.</td>\n",
       "      <td>Mochizuki, Jun</td>\n",
       "      <td>pandorahearts</td>\n",
       "      <td>junmochizuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149024</th>\n",
       "      <td>Here comes-- Daredevil. [Vol. 1] / [writer, Ma...</td>\n",
       "      <td>Waid, Mark, 1962-</td>\n",
       "      <td>herecomesdaredevil</td>\n",
       "      <td>markwaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>Anna Karenina</td>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>annakarenina</td>\n",
       "      <td>leotolstoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261708</th>\n",
       "      <td>Food wars! : shokugeki no soma. 1, Endless wil...</td>\n",
       "      <td>Tsukuda, Yuto, 1989-</td>\n",
       "      <td>foodwars</td>\n",
       "      <td>tsukudayuto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>Toot &amp; Puddle : wish you were here / by Holly ...</td>\n",
       "      <td>Hobbie, Holly</td>\n",
       "      <td>tootpuddle</td>\n",
       "      <td>hobbieholly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8590</th>\n",
       "      <td>Little Women: Little Women Series, Book 1</td>\n",
       "      <td>Louisa May Alcott</td>\n",
       "      <td>littlewomen</td>\n",
       "      <td>alcottlouisamay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395176</th>\n",
       "      <td>Kaguya-sama : love is war. 3 / [story &amp; art by...</td>\n",
       "      <td>Akasaka, Aka</td>\n",
       "      <td>kaguyasama</td>\n",
       "      <td>akaakasaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268480</th>\n",
       "      <td>Hacks for Minecrafters: Combat Edition: The Un...</td>\n",
       "      <td>Megan Miller</td>\n",
       "      <td>hacksforminecrafters</td>\n",
       "      <td>meganmiller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>Great Expectations (World Digital Library Edit...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>greatexpectations</td>\n",
       "      <td>charlesdickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15635</th>\n",
       "      <td>Can you see what I see? : once upon a time / b...</td>\n",
       "      <td>Wick, Walter, 1953-</td>\n",
       "      <td>canyouseewhatisee</td>\n",
       "      <td>walterwick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16404</th>\n",
       "      <td>Moomin : the complete Tove Jansson comic strip...</td>\n",
       "      <td>Jansson, Tove</td>\n",
       "      <td>moomin</td>\n",
       "      <td>janssontove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>A Tale of Two Cities</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>ataleoftwocities</td>\n",
       "      <td>charlesdickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>Mary Shelley</td>\n",
       "      <td>frankenstein</td>\n",
       "      <td>maryshelley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Martin Bridge : ready for takeoff! / written b...</td>\n",
       "      <td>Kerrin, Jessica Scott</td>\n",
       "      <td>martinbridge</td>\n",
       "      <td>jessicakerrinscott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33049</th>\n",
       "      <td>Green Lantern : wanted : Hal Jordan / Geoff Jo...</td>\n",
       "      <td>Johns, Geoff, 1973-</td>\n",
       "      <td>greenlantern</td>\n",
       "      <td>geoffjohns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368402</th>\n",
       "      <td>Miraculous. [1] / adapted by Cheryl Black and ...</td>\n",
       "      <td>Black, Cheryl</td>\n",
       "      <td>miraculous</td>\n",
       "      <td>blackcheryl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>The Wind in the Willows (Unabridged)</td>\n",
       "      <td>Kenneth Grahame</td>\n",
       "      <td>thewindinthewillows</td>\n",
       "      <td>grahamekenneth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121662</th>\n",
       "      <td>Sakura Hime : the legend of Princess Sakura. 1...</td>\n",
       "      <td>Tanemura, Arina</td>\n",
       "      <td>sakurahime</td>\n",
       "      <td>arinatanemura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73914</th>\n",
       "      <td>Do androids dream of electric sheep? [1] / [wr...</td>\n",
       "      <td>Dick, Philip K.</td>\n",
       "      <td>doandroidsdreamofelectricsheep</td>\n",
       "      <td>dickkphilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113532</th>\n",
       "      <td>Kamisama kiss. [2] / story &amp; art by Julietta S...</td>\n",
       "      <td>Suzuki, Julietta</td>\n",
       "      <td>kamisamakiss</td>\n",
       "      <td>juliettasuzuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>Rurouni Kenshin : Meiji swordsman romantic sto...</td>\n",
       "      <td>Watsuki, Nobuhiro</td>\n",
       "      <td>rurounikenshin</td>\n",
       "      <td>nobuhirowatsuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173140</th>\n",
       "      <td>Saga. [Volume one] / Brian K. Vaughan, writer ...</td>\n",
       "      <td>Vaughan, Brian K.</td>\n",
       "      <td>saga</td>\n",
       "      <td>briankvaughan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>Where's Waldo? : the great picture hunt / Mart...</td>\n",
       "      <td>Handford, Martin</td>\n",
       "      <td>whereswaldo</td>\n",
       "      <td>handfordmartin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254176</th>\n",
       "      <td>Big Nate: The Crowd Goes Wild!</td>\n",
       "      <td>Lincoln Peirce</td>\n",
       "      <td>bignate</td>\n",
       "      <td>lincolnpeirce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>War and Peace</td>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>warandpeace</td>\n",
       "      <td>leotolstoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>Pride and Prejudice (Unabridged)</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>prideandprejudice</td>\n",
       "      <td>austenjane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38027</th>\n",
       "      <td>Captain America : the death of Captain America...</td>\n",
       "      <td>Brubaker, Ed</td>\n",
       "      <td>captainamerica</td>\n",
       "      <td>brubakered</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title  \\\n",
       "8266    Fancy Nancy / by Jane O'Connor ; pictures by R...   \n",
       "12978   Yu-Gi-Oh! : duelist. Vol. 12, Magician vs. mag...   \n",
       "45510   The walking dead . [Volume 2, Miles behind us]...   \n",
       "285605               National Geographic Readers: Lizards   \n",
       "296436  Avatar: The Last Airbender - Smoke and Shadow,...   \n",
       "214882  The Year's Best Science Fiction: Fifth Annual ...   \n",
       "12113   Ranma 1/2 Vol. 34 / story & art by Rumiko Taka...   \n",
       "200986           Fly Guy presents : sharks / Tedd Arnold.   \n",
       "220080  Magi : the labyrinth of magic. 1 / story & art...   \n",
       "175438  Invincible : ultimate collection. Volume 2 / c...   \n",
       "140722  Pretty guardian : Sailor Moon. 1 / [Naoko Take...   \n",
       "1392    Dungeon : zenith. Vol. 2, The barbarian prince...   \n",
       "53431   Gantz. [2] / story and art by Hiroya Oku ; [tr...   \n",
       "405     Cork & Fuzz / by Dori Chaconas ; illustrated b...   \n",
       "6467    The night before Christmas / by Clement Clarke...   \n",
       "54909   Pluto : Urasawa x Tezuka. 001 / by Naoki Urasa...   \n",
       "206259  Hana-Kimi : for you in full blossom. 3 / story...   \n",
       "90682   Library wars : Love & war. 1 / story and art b...   \n",
       "262025  Noragami : stray god. Volume 1 / Adachitoka ; ...   \n",
       "4431    Pride and Prejudice (World Digital Library Edi...   \n",
       "75867   Rin-Ne. [1] / story and art by Rumiko Takahash...   \n",
       "11415             BACH, JS: Brandenburg Concertos, Vol  2   \n",
       "7116            Moby Dick (World Digital Library Edition)   \n",
       "87975                Pandora hearts. [2] / Jun Mochizuki.   \n",
       "149024  Here comes-- Daredevil. [Vol. 1] / [writer, Ma...   \n",
       "3556                                        Anna Karenina   \n",
       "261708  Food wars! : shokugeki no soma. 1, Endless wil...   \n",
       "3131    Toot & Puddle : wish you were here / by Holly ...   \n",
       "8590            Little Women: Little Women Series, Book 1   \n",
       "395176  Kaguya-sama : love is war. 3 / [story & art by...   \n",
       "268480  Hacks for Minecrafters: Combat Edition: The Un...   \n",
       "4952    Great Expectations (World Digital Library Edit...   \n",
       "15635   Can you see what I see? : once upon a time / b...   \n",
       "16404   Moomin : the complete Tove Jansson comic strip...   \n",
       "7271                                 A Tale of Two Cities   \n",
       "8476                                         Frankenstein   \n",
       "1007    Martin Bridge : ready for takeoff! / written b...   \n",
       "33049   Green Lantern : wanted : Hal Jordan / Geoff Jo...   \n",
       "368402  Miraculous. [1] / adapted by Cheryl Black and ...   \n",
       "3877                 The Wind in the Willows (Unabridged)   \n",
       "121662  Sakura Hime : the legend of Princess Sakura. 1...   \n",
       "73914   Do androids dream of electric sheep? [1] / [wr...   \n",
       "113532  Kamisama kiss. [2] / story & art by Julietta S...   \n",
       "2330    Rurouni Kenshin : Meiji swordsman romantic sto...   \n",
       "173140  Saga. [Volume one] / Brian K. Vaughan, writer ...   \n",
       "10625   Where's Waldo? : the great picture hunt / Mart...   \n",
       "254176                     Big Nate: The Crowd Goes Wild!   \n",
       "7494                                        War and Peace   \n",
       "4285                     Pride and Prejudice (Unabridged)   \n",
       "38027   Captain America : the death of Captain America...   \n",
       "\n",
       "                                 Creator                    CleanedTitle  \\\n",
       "8266                      O'Connor, Jane                      fancynancy   \n",
       "12978           Takahashi, Kazuki, 1961-                          yugioh   \n",
       "45510                    Kirkman, Robert                  thewalkingdead   \n",
       "285605                       Laura Marsh       nationalgeographicreaders   \n",
       "296436                    Gene Luen Yang                          avatar   \n",
       "214882                    Gardner Dozois      theyearsbestsciencefiction   \n",
       "12113           Takahashi, Rumiko, 1957-                          ranma1   \n",
       "200986                      Arnold, Tedd                  flyguypresents   \n",
       "220080                    Ōtaka, Shinobu                            magi   \n",
       "175438                   Kirkman, Robert                      invincible   \n",
       "140722                   Takeuchi, Naoko                  prettyguardian   \n",
       "1392                         Sfar, Joann                         dungeon   \n",
       "53431                        Oku, Hiroya                           gantz   \n",
       "405                Chaconas, Dori, 1938-                        corkfuzz   \n",
       "6467    Moore, Clement Clarke, 1779-1863         thenightbeforechristmas   \n",
       "54909              Urasawa, Naoki, 1960-                           pluto   \n",
       "206259                    Nakajo, Hisaya                        hanakimi   \n",
       "90682                        Yumi, Kiiro                     librarywars   \n",
       "262025                      Adachi, Toka                        noragami   \n",
       "4431                         Jane Austen               prideandprejudice   \n",
       "75867           Takahashi, Rumiko, 1957-                           rinne   \n",
       "11415              Johann Sebastian Bach                          bachjs   \n",
       "7116                     Herman Melville                        mobydick   \n",
       "87975                     Mochizuki, Jun                   pandorahearts   \n",
       "149024                 Waid, Mark, 1962-              herecomesdaredevil   \n",
       "3556                         Leo Tolstoy                    annakarenina   \n",
       "261708              Tsukuda, Yuto, 1989-                        foodwars   \n",
       "3131                       Hobbie, Holly                      tootpuddle   \n",
       "8590                   Louisa May Alcott                     littlewomen   \n",
       "395176                      Akasaka, Aka                      kaguyasama   \n",
       "268480                      Megan Miller            hacksforminecrafters   \n",
       "4952                     Charles Dickens               greatexpectations   \n",
       "15635                Wick, Walter, 1953-               canyouseewhatisee   \n",
       "16404                      Jansson, Tove                          moomin   \n",
       "7271                     Charles Dickens                ataleoftwocities   \n",
       "8476                        Mary Shelley                    frankenstein   \n",
       "1007               Kerrin, Jessica Scott                    martinbridge   \n",
       "33049                Johns, Geoff, 1973-                    greenlantern   \n",
       "368402                     Black, Cheryl                      miraculous   \n",
       "3877                     Kenneth Grahame             thewindinthewillows   \n",
       "121662                   Tanemura, Arina                      sakurahime   \n",
       "73914                    Dick, Philip K.  doandroidsdreamofelectricsheep   \n",
       "113532                  Suzuki, Julietta                    kamisamakiss   \n",
       "2330                   Watsuki, Nobuhiro                  rurounikenshin   \n",
       "173140                 Vaughan, Brian K.                            saga   \n",
       "10625                   Handford, Martin                     whereswaldo   \n",
       "254176                    Lincoln Peirce                         bignate   \n",
       "7494                         Leo Tolstoy                     warandpeace   \n",
       "4285                         Jane Austen               prideandprejudice   \n",
       "38027                       Brubaker, Ed                  captainamerica   \n",
       "\n",
       "             CleanedCreator  \n",
       "8266            connorjaneo  \n",
       "12978       kazukitakahashi  \n",
       "45510         kirkmanrobert  \n",
       "285605           lauramarsh  \n",
       "296436         geneluenyang  \n",
       "214882        dozoisgardner  \n",
       "12113       rumikotakahashi  \n",
       "200986           arnoldtedd  \n",
       "220080         shinobuōtaka  \n",
       "175438        kirkmanrobert  \n",
       "140722        naokotakeuchi  \n",
       "1392              joannsfar  \n",
       "53431             hiroyaoku  \n",
       "405            chaconasdori  \n",
       "6467     clarkeclementmoore  \n",
       "54909          naokiurasawa  \n",
       "206259         hisayanakajo  \n",
       "90682             kiiroyumi  \n",
       "262025           adachitoka  \n",
       "4431             austenjane  \n",
       "75867       rumikotakahashi  \n",
       "11415   bachjohannsebastian  \n",
       "7116         hermanmelville  \n",
       "87975          junmochizuki  \n",
       "149024             markwaid  \n",
       "3556             leotolstoy  \n",
       "261708          tsukudayuto  \n",
       "3131            hobbieholly  \n",
       "8590        alcottlouisamay  \n",
       "395176           akaakasaka  \n",
       "268480          meganmiller  \n",
       "4952         charlesdickens  \n",
       "15635            walterwick  \n",
       "16404           janssontove  \n",
       "7271         charlesdickens  \n",
       "8476            maryshelley  \n",
       "1007     jessicakerrinscott  \n",
       "33049            geoffjohns  \n",
       "368402          blackcheryl  \n",
       "3877         grahamekenneth  \n",
       "121662        arinatanemura  \n",
       "73914           dickkphilip  \n",
       "113532       juliettasuzuki  \n",
       "2330        nobuhirowatsuki  \n",
       "173140        briankvaughan  \n",
       "10625        handfordmartin  \n",
       "254176        lincolnpeirce  \n",
       "7494             leotolstoy  \n",
       "4285             austenjane  \n",
       "38027            brubakered  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure data matches \n",
    "merged_df[['Title', 'Creator', 'CleanedTitle', 'CleanedCreator']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609183, 239)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.to_csv('data/cleaned_months_with_type_2005.csv', index=False)\n",
    "merged_df.to_csv('data/cleaned_months_no_whitespace_2005.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some additional exploration: \n",
    "\n",
    "We note that of the materials we have, most of them are physical books, followed by ebooks, audiobooks, sounddiscs. A small proportion is composed of other with both physical and digital classes and finally there are few videodiscs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>295250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>186458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Digital</td>\n",
       "      <td>AUDIOBOOK</td>\n",
       "      <td>73360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Physical</td>\n",
       "      <td>SOUNDDISC</td>\n",
       "      <td>44315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Digital</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Physical</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Physical</td>\n",
       "      <td>VIDEODISC</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UsageClass MaterialType   count\n",
       "0   Physical         BOOK  295250\n",
       "1    Digital        EBOOK  186458\n",
       "2    Digital    AUDIOBOOK   73360\n",
       "3   Physical    SOUNDDISC   44315\n",
       "4    Digital        OTHER    5186\n",
       "5   Physical        OTHER    4244\n",
       "6   Physical    VIDEODISC     370"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = merged_df[['UsageClass', 'MaterialType']].value_counts().reset_index()\n",
    "pairs.head(pairs.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that the date in CheckoutDate does contain the first checkout date. It should since we sorted our dataframe by CheckoutDate before processing, and here we verify this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Format CheckoutDate column to match column name\n",
    "merged_df['CheckoutDate_str'] = merged_df['CheckoutDate'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "#Get indices of first and last months\n",
    "first_index= merged_df.columns.get_loc('04/01/2005')\n",
    "last_index =  merged_df.columns.get_loc('04/01/2024')\n",
    "\n",
    "#Create new dataframe with just month data to process\n",
    "checkouts = merged_df.iloc[:,first_index:last_index+1]\n",
    "\n",
    "#Function to grab the first nonzero column in each row of checkouts\n",
    "def find_first_nonzero_column(row):\n",
    "    return row[row.ne(0)].index[0]\n",
    "\n",
    "#Apply function to each row in df_sample\n",
    "merged_df['first_nonzero_month'] = checkouts.apply(find_first_nonzero_column, axis=1)\n",
    "\n",
    "#Check that the values match in each column\n",
    "checking = merged_df['first_nonzero_month']== merged_df['CheckoutDate']\n",
    "#This prints True if all match; false otherwise\n",
    "print(any(checking))\n",
    "\n",
    "#Drop the columns added\n",
    "merged_df = merged_df.drop(columns=['CheckoutDate_str', 'first_nonzero_month'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to clean the Subject column and assign specific genres to each book. We do so via the classify_genre, in which we lower the Subject column and find matches with our predefined genre list. Note that since we want just one genre per book, the function prioritizes genres in the order they are listed with very specific things first and more generic genres like \"fiction\" and \"nonfiction\" last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data again or rename as df for convenience\n",
    "#df = merged_df\n",
    "#df = pd.read_csv('data/cleaned_months_with_type_2005.csv')\n",
    "df = pd.read_csv('data/cleaned_months_no_whitespace_2005.csv')\n",
    "df['CheckoutDate'] = pd.to_datetime(df['CheckoutDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609183, 239)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CleanedSubject'] = df['Subjects'].str.lower().str.strip()\n",
    "\n",
    "# Define the list of genres in the desired hierarchy order\n",
    "genres = ['juvenile', 'young adult', 'fantasy', 'romance', 'thriller',\\\n",
    "            'horror', 'mystery', 'science fiction', 'biography', \\\n",
    "                'history', 'novel', 'nonfiction', 'fiction']\n",
    "# Make list of true genre names we want to consider for genre in genres\n",
    "# This list aligns with the placement in genres\n",
    "# For example, fantasy becomes fantasy/sci-fi as does science fiction\n",
    "genres_match = ['juvenile', 'young adult', 'fantasy/sci-fi', 'romance', 'horror/thriller',\\\n",
    "            'horror/thriller', 'mystery', 'fantasy/sci-fi', 'biography', \\\n",
    "                'history', 'fiction', 'nonfiction', 'fiction']\n",
    "#Make another list of the desired final genre list without duplicates\n",
    "genres_final = ['juvenile', 'young adult', 'fantasy/sci-fi', 'romance', \\\n",
    "                'horror/thriller', 'mystery', 'biography', 'history', \\\n",
    "                 'nonfiction', 'fiction']\n",
    "\n",
    "#Create dictionary combining genres found in Subject string\n",
    "#  with genre names we want to use\n",
    "genres_final_dict = dict(zip(genres, genres_match))\n",
    "\n",
    "# Create a dictionary for priority of each genre\n",
    "priority = {genre: i for i, genre in enumerate(genres_final)}\n",
    "\n",
    "# Function to classify genre based on the CleanedSubject column\n",
    "def classify_genre(cleaned_subject):\n",
    "    if pd.isna(cleaned_subject):  # If the entry is NaN\n",
    "        return 'other'\n",
    "\n",
    "    # Convert the cleaned_subject to lower case for case-insensitive matching\n",
    "    cleaned_subject = cleaned_subject.lower()\n",
    "\n",
    "    # Create a dictionary for priority of each genre\n",
    "    #priority = {genre: i for i, genre in enumerate(genres)} \n",
    "\n",
    "    # Find all matching genres in the cleaned_subject string\n",
    "    #found_genres = [genre for genre in genres if genre in cleaned_subject]\n",
    "    found_genres = [genres_final_dict[genre] for genre in genres if genre in cleaned_subject]\n",
    "\n",
    "\n",
    "    if not found_genres:  # If no genre is found\n",
    "        return 'other'\n",
    "    \n",
    "\n",
    "    # Sort genres based on their priority\n",
    "    found_genres.sort(key=lambda g: priority[g])\n",
    "\n",
    "    # Return the genre with the highest priority\n",
    "    return found_genres[0]\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['Genre'] = df['CleanedSubject'].apply(classify_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the distribution of the genres, and see that out of the ~610000 possibilities, we have around 122000 'other' options. Thus, most of the books can be characterized into one of the possible genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>juvenile</td>\n",
       "      <td>123928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>122386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fiction</td>\n",
       "      <td>82675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nonfiction</td>\n",
       "      <td>53144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biography</td>\n",
       "      <td>42914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fantasy/sci-fi</td>\n",
       "      <td>37867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mystery</td>\n",
       "      <td>35584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>history</td>\n",
       "      <td>32934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>romance</td>\n",
       "      <td>31169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>horror/thriller</td>\n",
       "      <td>26350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>young adult</td>\n",
       "      <td>20232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Genre   count\n",
       "0          juvenile  123928\n",
       "1             other  122386\n",
       "2           fiction   82675\n",
       "3        nonfiction   53144\n",
       "4         biography   42914\n",
       "5    fantasy/sci-fi   37867\n",
       "6           mystery   35584\n",
       "7           history   32934\n",
       "8           romance   31169\n",
       "9   horror/thriller   26350\n",
       "10      young adult   20232"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts = df['Genre'].value_counts().reset_index()\n",
    "\n",
    "genre_counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to aggregate the number of checkouts in the first year, with the first checkout date denoting the publication date. We do so via the sum_checkouts_first_year function defined below, which is applied to each row in our dataframe. This function grabs the first checkoutdate of each item, located in the CheckoutDate column, and calculates the date that is a year out. From the columns_dict dictionary, which has keys the column names of df and values the corresponding indices, we can them grab the appropriate columns indices to sum over to get the total number of checkouts in the first year.  Note that if the first checkout date is after 09/01/2023, we only sum the partial year up to 08/01/2024. We store the result into a new column \"FirstYearCheckout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary of column, index pairs to \n",
    "indices = list(range(len(df.columns)))\n",
    "columns = df.columns\n",
    "columns_dict = dict(zip(columns, indices))\n",
    "\n",
    "\n",
    "#Function to sum checkouts from first checkout date to one year later\n",
    "def sum_checkouts_first_year(row):\n",
    "    first_checkout = row['CheckoutDate'] #Get first checkout date\n",
    "    first_index= columns_dict[first_checkout.strftime('%m/%d/%Y')] #Convert to column name form and get index of column\n",
    "    end_year  = (first_checkout.replace(year=first_checkout.year +1)).strftime('%m/%d/%Y') #Add one to year to get end date\n",
    "    if end_year in columns_dict: #Get index of end year column\n",
    "        end_index= columns_dict[end_year]\n",
    "    else:\n",
    "        #Get last possible month of data and include it; which gives the +1\n",
    "        end_index =columns_dict['04/01/2024'] +1 \n",
    "    checkout_sum = 0\n",
    "    for i in range(first_index, end_index): #Sum over all checkouts in range\n",
    "        checkout_sum += row.iloc[i]\n",
    "    return checkout_sum\n",
    "\n",
    "df['FirstYearCheckouts'] = df.apply(sum_checkouts_first_year, axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next task it get the sum of checkouts per month per author in the year prior to the first checkout. Note that if the start of the previous year is outside the scope of the data we have, we do a partial sum of whatever months we are able; e.g. if the checkout date was 01/01/2006, then we would sum the authors checkouts from 04/01/2005 to 12/01/2005 since our first checkout is April 2005. To create the previous checkout column, we first get the sum of all book checkouts per month per author, which is stored in author_summed. Then for each row in our dataframe, we get the first checkout date and sum the appriopriate columns in author_summed to get total checkouts in the previous year for author corresponding to that row. We store the result into a column named PreviousYearCheckouts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanedCreator</th>\n",
       "      <th>04/01/2005</th>\n",
       "      <th>05/01/2005</th>\n",
       "      <th>06/01/2005</th>\n",
       "      <th>07/01/2005</th>\n",
       "      <th>08/01/2005</th>\n",
       "      <th>09/01/2005</th>\n",
       "      <th>10/01/2005</th>\n",
       "      <th>11/01/2005</th>\n",
       "      <th>12/01/2005</th>\n",
       "      <th>...</th>\n",
       "      <th>07/01/2023</th>\n",
       "      <th>08/01/2023</th>\n",
       "      <th>09/01/2023</th>\n",
       "      <th>10/01/2023</th>\n",
       "      <th>11/01/2023</th>\n",
       "      <th>12/01/2023</th>\n",
       "      <th>01/01/2024</th>\n",
       "      <th>02/01/2024</th>\n",
       "      <th>03/01/2024</th>\n",
       "      <th>04/01/2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaguirre</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaakerdavid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaanuel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aabalaskovits</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CleanedCreator  04/01/2005  05/01/2005  06/01/2005  07/01/2005  08/01/2005  \\\n",
       "0             aa           0           0           0           0           0   \n",
       "1      aaaguirre           0           0           0           0           0   \n",
       "2    aaakerdavid           0           0           0           0           0   \n",
       "3        aaanuel           0           0           0           0           0   \n",
       "4  aabalaskovits           0           0           0           0           0   \n",
       "\n",
       "   09/01/2005  10/01/2005  11/01/2005  12/01/2005  ...  07/01/2023  \\\n",
       "0           0           0           0           0  ...           0   \n",
       "1           0           0           0           0  ...           0   \n",
       "2           0           0           0           0  ...           0   \n",
       "3           0           0           0           0  ...           0   \n",
       "4           0           0           0           0  ...           0   \n",
       "\n",
       "   08/01/2023  09/01/2023  10/01/2023  11/01/2023  12/01/2023  01/01/2024  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           2           0           0           1           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           2           0           0   \n",
       "4           0           0           1           0           1           1   \n",
       "\n",
       "   02/01/2024  03/01/2024  04/01/2024  \n",
       "0           0           0           0  \n",
       "1           1           3           0  \n",
       "2           0           0           0  \n",
       "3           0           0           0  \n",
       "4           0           1           0  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get index range for columns of interest\n",
    "first_index= columns_dict['04/01/2005']\n",
    "last_index = columns_dict['04/01/2024']\n",
    "\n",
    "#Get dataframe with CleanedCreator column plus all corresponding months column\n",
    "months_df = df.iloc[:, first_index:last_index+1 ]\n",
    "months_df.insert(loc = 0,column='CleanedCreator', value=df.CleanedCreator)\n",
    "\n",
    "#Get dataframe with CleanedCreator column plus all corresponding months column\n",
    "months_df = df.iloc[:, first_index:last_index+1 ]\n",
    "months_df.insert(loc = 0,column='CleanedCreator', value=df.CleanedCreator)\n",
    "\n",
    "#Sum the checkouts for each author in each month\n",
    "# For each author, we have all months columns filled with all checkouts in that month\n",
    "author_summed = months_df.groupby('CleanedCreator').sum()\n",
    "\n",
    "author_summed = author_summed.reset_index()\n",
    "\n",
    "author_summed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary of column, index pairs for author_summed\n",
    "indices = list(range(len(author_summed.columns)))\n",
    "columns = author_summed.columns\n",
    "author_columns_dict = dict(zip(columns, indices))\n",
    "\n",
    "#Create dictionary to get row of author_summed by CleanedCreator \n",
    "author_dict = dict(zip(author_summed.CleanedCreator, author_summed.index))\n",
    "\n",
    "# Function to calcuate number of checkouts of the author in the year before first checkout\n",
    "def previous_year_sum(row):\n",
    "    first_checkout = row['CheckoutDate']\n",
    "    author = row['CleanedCreator']\n",
    "    idx = author_dict[author]\n",
    "    end_index= author_columns_dict[first_checkout.strftime('%m/%d/%Y')] #Convert to column name form and get index of column\n",
    "    previous_year  = (first_checkout.replace(year=first_checkout.year -1)).strftime('%m/%d/%Y') #Add one to year to get end date\n",
    "    if previous_year in author_columns_dict: #Get index of end year column\n",
    "        first_index= author_columns_dict[previous_year]\n",
    "    else:\n",
    "        # Get first possible month of data\n",
    "        first_index =author_columns_dict['04/01/2005']\n",
    "    checkout_sum = 0\n",
    "    for i in range(first_index, end_index): #Sum over all checkouts in range\n",
    "        checkout_sum += author_summed.iloc[idx, i]\n",
    "    return checkout_sum\n",
    "\n",
    "\n",
    "df['PreviousYearCheckouts'] = df.apply(previous_year_sum, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our clean data, we want to create a train test split. We create and drop some columns to make processing easier later and then make a train test split. Note that we will have books with checkout dates before April 2006 in both training and testing data sets, which will need care in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for month and year to be used as possible features later\n",
    "df['CheckoutMonth'] = df['CheckoutDate'].dt.month\n",
    "df['CheckoutYear'] = df['CheckoutDate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the columns of all the months of the form MM/DD/YYYY\n",
    "indices = list(range(len(df.columns)))\n",
    "columns = df.columns\n",
    "columns_dict = dict(zip(columns, indices))\n",
    "\n",
    "#Find the indices of the first and last columns\n",
    "first_index= columns_dict['04/01/2005']\n",
    "last_index = columns_dict['04/01/2024']\n",
    "\n",
    "dropped_months = columns[first_index:last_index+1].to_list()\n",
    "\n",
    "dropped_columns = [*dropped_months, 'Subjects', 'CleanedSubject',\\\n",
    "                   'CleanedTitle', 'CleanedCreator', 'PublicationYear', 'CheckoutDate']\n",
    "\n",
    "df = df.drop(columns=dropped_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>Genre</th>\n",
       "      <th>FirstYearCheckouts</th>\n",
       "      <th>PreviousYearCheckouts</th>\n",
       "      <th>CheckoutMonth</th>\n",
       "      <th>CheckoutYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fancy Nancy / by Jane O'Connor ; pictures by R...</td>\n",
       "      <td>O'Connor, Jane</td>\n",
       "      <td>HarperCollins,</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>juvenile</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yu-Gi-Oh! : duelist. Vol. 12, Magician vs. mag...</td>\n",
       "      <td>Takahashi, Kazuki, 1961-</td>\n",
       "      <td>Viz Media,</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>juvenile</td>\n",
       "      <td>604</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The walking dead . [Volume 2, Miles behind us]...</td>\n",
       "      <td>Kirkman, Robert</td>\n",
       "      <td>Image Comics,</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>horror/thriller</td>\n",
       "      <td>169</td>\n",
       "      <td>772</td>\n",
       "      <td>10</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>National Geographic Readers: Lizards</td>\n",
       "      <td>Laura Marsh</td>\n",
       "      <td>Random House, Inc.</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>juvenile</td>\n",
       "      <td>186</td>\n",
       "      <td>504</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avatar: The Last Airbender - Smoke and Shadow,...</td>\n",
       "      <td>Gene Luen Yang</td>\n",
       "      <td>Random House, Inc.</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>juvenile</td>\n",
       "      <td>217</td>\n",
       "      <td>2997</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Fancy Nancy / by Jane O'Connor ; pictures by R...   \n",
       "1  Yu-Gi-Oh! : duelist. Vol. 12, Magician vs. mag...   \n",
       "2  The walking dead . [Volume 2, Miles behind us]...   \n",
       "3               National Geographic Readers: Lizards   \n",
       "4  Avatar: The Last Airbender - Smoke and Shadow,...   \n",
       "\n",
       "                    Creator           Publisher UsageClass MaterialType  \\\n",
       "0            O'Connor, Jane      HarperCollins,   Physical         BOOK   \n",
       "1  Takahashi, Kazuki, 1961-          Viz Media,   Physical         BOOK   \n",
       "2           Kirkman, Robert       Image Comics,   Physical         BOOK   \n",
       "3               Laura Marsh  Random House, Inc.    Digital        EBOOK   \n",
       "4            Gene Luen Yang  Random House, Inc.    Digital        EBOOK   \n",
       "\n",
       "             Genre  FirstYearCheckouts  PreviousYearCheckouts  CheckoutMonth  \\\n",
       "0         juvenile                 131                      0              3   \n",
       "1         juvenile                 604                      0              8   \n",
       "2  horror/thriller                 169                    772             10   \n",
       "3         juvenile                 186                    504              7   \n",
       "4         juvenile                 217                   2997             10   \n",
       "\n",
       "   CheckoutYear  \n",
       "0          2006  \n",
       "1          2006  \n",
       "2          2008  \n",
       "3          2015  \n",
       "4          2015  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 80% training data and 20% testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2,\\\n",
    "                                      shuffle=True, random_state=216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('data/cleaned_train_2005.csv', index=False)\n",
    "df_test.to_csv('data/cleaned_test_2005.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487346, 10)\n",
      "(121837, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
