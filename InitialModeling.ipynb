{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import warnings\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>UsageClass</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>Genre</th>\n",
       "      <th>FirstYearCheckouts</th>\n",
       "      <th>PreviousYearCheckouts</th>\n",
       "      <th>CheckoutMonth</th>\n",
       "      <th>CheckoutYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whose poop is that? / Darrin Lunde ; illustrat...</td>\n",
       "      <td>Lunde, Darrin P.</td>\n",
       "      <td>Charlesbridge,</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>juvenile</td>\n",
       "      <td>59</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Power of Language: How the Codes We Use to...</td>\n",
       "      <td>Viorica Marian</td>\n",
       "      <td>Penguin Group (USA), Inc.</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>nonfiction</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If I Were Your Woman</td>\n",
       "      <td>Donna Hill</td>\n",
       "      <td>Harlequin Enterprises, Ltd.</td>\n",
       "      <td>Digital</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>romance</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where are the Great Pyramids? / by Dorothy and...</td>\n",
       "      <td>Hoobler, Dorothy</td>\n",
       "      <td>Grosset &amp; Dunlap, an imprint of Penguin Random...</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>juvenile</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donde cantan las ballenas / Sara Jaramillo Kli...</td>\n",
       "      <td>Jaramillo Klinkert, Sara</td>\n",
       "      <td>Lumen,</td>\n",
       "      <td>Physical</td>\n",
       "      <td>BOOK</td>\n",
       "      <td>fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Whose poop is that? / Darrin Lunde ; illustrat...   \n",
       "1  The Power of Language: How the Codes We Use to...   \n",
       "2                               If I Were Your Woman   \n",
       "3  Where are the Great Pyramids? / by Dorothy and...   \n",
       "4  Donde cantan las ballenas / Sara Jaramillo Kli...   \n",
       "\n",
       "                    Creator  \\\n",
       "0          Lunde, Darrin P.   \n",
       "1            Viorica Marian   \n",
       "2                Donna Hill   \n",
       "3          Hoobler, Dorothy   \n",
       "4  Jaramillo Klinkert, Sara   \n",
       "\n",
       "                                           Publisher UsageClass MaterialType  \\\n",
       "0                                     Charlesbridge,   Physical         BOOK   \n",
       "1                          Penguin Group (USA), Inc.    Digital        EBOOK   \n",
       "2                        Harlequin Enterprises, Ltd.    Digital        EBOOK   \n",
       "3  Grosset & Dunlap, an imprint of Penguin Random...   Physical         BOOK   \n",
       "4                                             Lumen,   Physical         BOOK   \n",
       "\n",
       "        Genre  FirstYearCheckouts  PreviousYearCheckouts  CheckoutMonth  \\\n",
       "0    juvenile                  59                    124              2   \n",
       "1  nonfiction                  57                      0              4   \n",
       "2     romance                   3                     47              3   \n",
       "3    juvenile                  24                     19             11   \n",
       "4     fiction                   1                      0              9   \n",
       "\n",
       "   CheckoutYear  \n",
       "0          2017  \n",
       "1          2023  \n",
       "2          2008  \n",
       "3          2015  \n",
       "4          2021  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in cleaned data\n",
    "df_train = pd.read_csv('data/cleaned_train_2005.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: \n",
    "\n",
    "For our baseline model, we predict the number of first year checkouts for a library item as the average of all the first year checkout data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make KFold object to be used on training dataset\n",
    "kfold = KFold(n_splits = 5,\n",
    "              shuffle = True,\n",
    "              random_state = 216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = np.zeros(5)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df_train, df_train['FirstYearCheckouts'])):\n",
    "    ## get the kfold training and holdout data\n",
    "    X_tt = df_train.iloc[train_index]\n",
    "    X_ho = df_train.iloc[test_index]\n",
    "\n",
    "    #Get average of the first year checkouts for our train set \n",
    "    baseline_pred = np.ones(len(X_ho)) * X_tt['FirstYearCheckouts'].mean() \n",
    "\n",
    "    ## Record the rmses\n",
    "    rmses[i] = root_mean_squared_error(X_ho['FirstYearCheckouts'], baseline_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120.72933696 120.74623903 114.23789139 115.63958754 111.41788744]\n",
      "116.55418847177882\n"
     ]
    }
   ],
   "source": [
    "print(rmses)\n",
    "print(rmses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of first year checkouts for the whole dataset is 44.82706356778149\n",
      "The minimum and maximum first year checkouts in our dataset are 1 and 9633 respectively\n"
     ]
    }
   ],
   "source": [
    "print('The average number of first year checkouts for the whole dataset is', df_train['FirstYearCheckouts'].mean())\n",
    "print('The minimum and maximum first year checkouts in our dataset are', df_train['FirstYearCheckouts'].min(), \\\n",
    "      'and', df_train['FirstYearCheckouts'].max(), 'respectively')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Modeling Attempt: Linear Regression\n",
    "\n",
    "For our first model, we will consider linear regression. We will train on most of the features, including Publisher, which we first clean and then one-hot encode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_publisher(text): \n",
    "    #Remove non-digit or alphabetical characters; leave whitespace\n",
    "    text = re.sub(r'[^\\w]','',text)\n",
    "    # Strip any leading/trailing whitespace and make lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanedPublisher</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>randomhouseinc</td>\n",
       "      <td>24592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harpercollinspublishersinc</td>\n",
       "      <td>18052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>penguingroupusainc</td>\n",
       "      <td>18031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>booksontape</td>\n",
       "      <td>11592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macmillanpublishers</td>\n",
       "      <td>11230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CleanedPublisher  count\n",
       "0              randomhouseinc  24592\n",
       "1  harpercollinspublishersinc  18052\n",
       "2          penguingroupusainc  18031\n",
       "3                 booksontape  11592\n",
       "4         macmillanpublishers  11230"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['CleanedPublisher'] = df_train['Publisher'].apply(clean_publisher)\n",
    "pubs = df_train['CleanedPublisher'].value_counts().reset_index()\n",
    "pubs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings we filter from the  cleaned publisher colum\n",
    "publishers = ['tantor', 'penguin', 'randomhouse', 'harpercollins', 'harper', \\\n",
    "              'booksontape', 'listeninglibrary', 'schuster', 'blackstone', \n",
    "              'hachette', 'scholastic', 'harlequin', 'macmillan',\\\n",
    "                'mifflin', 'brilliance', 'lightningsource', 'recordedbooks' ]\n",
    "\n",
    "# Mapping of strings in publishers to the publisher categories we will actually use \n",
    "publishers_mapped = ['recorded books', 'penguin random house', 'penguin random house',\\\n",
    "                     'harpercollins', 'harpercollins', 'penguin random house', 'penguin random house', \\\n",
    "                      'simon & schuster', 'blackstone', 'hachette', \\\n",
    "                      'scholastic', 'harlequin', 'macmillan', 'harpercollins', \\\n",
    "                        'brilliance', 'lightning source', 'recorded books']\n",
    "\n",
    "# The final list of the publisher categories used \n",
    "publishers_final =['recorded books', 'penguin random house', 'harpercollins', 'simon & schuster', \\\n",
    "                   'blackstone' , 'scholastic', 'macmillan', 'hachette', 'harlequin',\\\n",
    "                    'brilliance', 'lightning source', 'other publisher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary combining genres found in Subject string\n",
    "#  with genre names we want to use\n",
    "pubs_final_dict = dict(zip(publishers, publishers_mapped))\n",
    "\n",
    "# Create a dictionary for priority of each genre\n",
    "priority = {pubs: i for i, pubs in enumerate(publishers_final)}\n",
    "\n",
    "# Function to classify genre based on the CleanedSubject column\n",
    "def classify_publishers(cleaned_pubs):\n",
    "    if pd.isna(cleaned_pubs):  # If the entry is NaN\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "    # Find all matching publishers in the cleaned_pubs string\n",
    "    found_pubs = [pubs_final_dict[pubs] for pubs in publishers if pubs in cleaned_pubs]\n",
    "\n",
    "\n",
    "    if not found_pubs:  # If no publisher is found\n",
    "        return 'other publisher'\n",
    "    \n",
    "\n",
    "    # Sort genres based on their priority\n",
    "    found_pubs.sort(key=lambda g: priority[g])\n",
    "\n",
    "    # Return the genre with the highest priority\n",
    "    return found_pubs[0]\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df_train['CleanedPublisher'] = df_train['CleanedPublisher'].apply(classify_publishers)\n",
    "df_train = df_train.drop(columns = ['Publisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of cateories for columns of one-hot encoding\n",
    "genre_list = df_train['Genre'].unique().tolist()\n",
    "material_list = df_train['MaterialType'].unique().tolist()\n",
    "#publisher_list = df_train['CleanedPublisher'].unique().tolist()\n",
    "\n",
    "# One-hot encoding of 'Genre' variable\n",
    "df_train[genre_list] = pd.get_dummies(df_train['Genre'])\n",
    "\n",
    "# One-hot encoding of 'MaterialType' variables\n",
    "df_train[material_list] = pd.get_dummies(df_train['MaterialType'])\n",
    "\n",
    "# One-hot encoding of 'CleanedPublisher' variable\n",
    "#df_train[publisher_list] = pd.get_dummies(df_train['CleanedPublisher'])\n",
    "\n",
    "#One hot encode UsageClass into single column with 1 indicating 'Physical' and 0 indicating 'Digital'\n",
    "df_train['UsageClass'] = pd.get_dummies(df_train['UsageClass'])['Physical']\n",
    "df_train = df_train.drop(columns = ['Genre', 'MaterialType'])\n",
    "#df_train = df_train.drop(columns = ['Genre', 'MaterialType', 'CleanedPublisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Creator', 'UsageClass', 'FirstYearCheckouts',\n",
       "       'PreviousYearCheckouts', 'CheckoutMonth', 'CheckoutYear',\n",
       "       'CleanedPublisher', 'juvenile', 'nonfiction', 'romance', 'fiction',\n",
       "       'mystery', 'other', 'horror/thriller', 'history', 'biography',\n",
       "       'fantasy/sci-fi', 'young adult', 'BOOK', 'EBOOK', 'AUDIOBOOK',\n",
       "       'SOUNDDISC', 'OTHER', 'VIDEODISC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features we want to train our linear regression on\n",
    "features=['UsageClass', 'PreviousYearCheckouts', 'CheckoutMonth', 'CheckoutYear', 'juvenile', 'nonfiction', 'romance', 'fiction',\n",
    "       'mystery', 'other', 'horror/thriller', 'history', 'biography',\n",
    "       'fantasy/sci-fi', 'young adult', 'BOOK', 'EBOOK', 'AUDIOBOOK',\n",
    "       'SOUNDDISC', 'OTHER', 'VIDEODISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold split\n",
    "kfold = KFold(n_splits = 5,\n",
    "              shuffle = True,\n",
    "              random_state = 216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array to store rmse\n",
    "rmse = np.zeros(5)\n",
    "\n",
    "# Initialize LinearRegression Model\n",
    "lr = LinearRegression()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df_train, df_train['FirstYearCheckouts'])):\n",
    "\n",
    "    ## get the kfold training and holdout data\n",
    "    X_tt = df_train.iloc[train_index]\n",
    "    X_ho = df_train.iloc[test_index]\n",
    "\n",
    "    ## Fit model\n",
    "    lr.fit(X_tt[features], X_tt['FirstYearCheckouts'])\n",
    "\n",
    "    ## Generate predictions on the holdout set\n",
    "    lr_preds = lr.predict(X_ho[features])\n",
    "\n",
    "    ## Record the rmses\n",
    "    rmses[i] = root_mean_squared_error(X_ho['FirstYearCheckouts'], lr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118.70998867 118.79886248 112.47832067 113.86938046 109.57269062]\n"
     ]
    }
   ],
   "source": [
    "print(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.68584857752083\n"
     ]
    }
   ],
   "source": [
    "print(rmses.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis worked without taking into account Publisher; we now do the same modeling but adding the publisher as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of cateories for columns of one-hot encoding\n",
    "publisher_list = df_train['CleanedPublisher'].unique().tolist()\n",
    "\n",
    "# One-hot encoding of 'CleanedPublisher' variable\n",
    "df_train[publisher_list] = pd.get_dummies(df_train['CleanedPublisher'])\n",
    "df_train = df_train.drop(columns = ['CleanedPublisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features=['UsageClass', 'PreviousYearCheckouts', 'CheckoutMonth', 'CheckoutYear', 'juvenile', 'nonfiction', 'romance', 'fiction',\n",
    "       'mystery', 'other', 'horror/thriller', 'history', 'biography',\n",
    "       'fantasy/sci-fi', 'young adult', 'BOOK', 'EBOOK', 'AUDIOBOOK',\n",
    "       'SOUNDDISC', 'OTHER', 'VIDEODISC','other publisher', 'penguin random house', 'harlequin',\n",
    "       'blackstone', 'harpercollins', 'brilliance', 'macmillan',\n",
    "       'simon & schuster', 'recorded books', 'hachette', 'lightning source',\n",
    "       'scholastic' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold split\n",
    "kfold = KFold(n_splits = 5,\n",
    "              shuffle = True,\n",
    "              random_state = 216)\n",
    "\n",
    "# Array to store rmse\n",
    "rmse = np.zeros(5)\n",
    "\n",
    "# Initialize LinearRegression Model\n",
    "lr = LinearRegression()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kfold.split(df_train, df_train['FirstYearCheckouts'])):\n",
    "\n",
    "    ## get the kfold training and holdout data\n",
    "    X_tt = df_train.iloc[train_index]\n",
    "    X_ho = df_train.iloc[test_index]\n",
    "\n",
    "    ## Fit model\n",
    "    lr.fit(X_tt[new_features], X_tt['FirstYearCheckouts'])\n",
    "\n",
    "    ## Generate predictions on the holdout set\n",
    "    lr_preds = lr.predict(X_ho[new_features])\n",
    "\n",
    "    ## Record the rmses\n",
    "    rmses[i] = root_mean_squared_error(X_ho['FirstYearCheckouts'], lr_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118.38257533 118.47005855 112.17974951 113.56904321 109.25002301]\n",
      "114.37028992054891\n"
     ]
    }
   ],
   "source": [
    "print(rmses)\n",
    "print(rmses.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
